{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NewtonMethod.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import autograd as ad\n","from autograd import grad, jacobian, hessian\n","import autograd.numpy as np"],"metadata":{"id":"UekZPjg3hUtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def func1(x):\n","    \"\"\"\n","    Objective function 1 whose roots are the ones to find.\n","    \"\"\"\n","    return (x[0]+x[1]+x[2]-5)**2 + 3*(x[0]-x[1])**2 + 2*(x[1]-2*x[2])**2"],"metadata":{"id":"h-VJ49-cRXg1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def func2(x):\n","    \"\"\"\n","    Objective function 2 whose roots are the ones to find.\n","    \"\"\"\n","    return 100*((x[1]-x[0])**2) + (1-x[0])**2"],"metadata":{"id":"ycIhmeKAfOrp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"PdnnqzUzRaJK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"PSfs4RthRaLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jacobian_func = jacobian(func1)\n","hessian_func = hessian(func1)"],"metadata":{"id":"gvb1IqGmRaNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def NewtonMethod(func, jacob_f, hessian_f, w0, epsilon = 0.001, nMax = 100):\n","    #Initializating variables, iter_x, iter_x are used to plot results\n","    i = 0\n","    # iter_x, iter_y, iter_count = np.empty(0),np.empty(0),np.empty(0)\n","    \n","    jacobian_w = jacob_f(w0)\n","    hessian_w_inv = np.linalg.inv(hessian_f(w0))\n","    D = np.dot(hessian_w_inv, jacobian_w)\n","    error = np.linalg.norm(w0 - (w0 - D))\n","    #Looping as long as error is greater than epsilon or maximum number of iterations is not reached:\n","    while error > epsilon and i < nMax:\n","        i +=1\n","        # iter_x = np.append(iter_x,x)\n","        # iter_y = np.append(iter_y,func(x))\n","        # iter_count = np.append(iter_count ,i)\n","        w0 = (w0 - D)\n","        jacobian_w = jacob_f(w0)\n","        hessian_w_inv = np.linalg.inv(hessian_f(w0))\n","        D = np.dot(hessian_w_inv, jacobian_w)\n","        error = np.linalg.norm(w0 - (w0 - D))\n","        print(\"Iteration Number : {}\".format(i))\n","        print(\"Error : {}\".format(error))\n","        print(\"Minimizer : {}\".format(w0))"],"metadata":{"id":"TutyLHXItPr2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["W0 = np.array([0, 0, 0], dtype=float)\n","NewtonMethod(func1, jacobian_func, hessian_func, W0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVWWzoCoQ2KF","outputId":"8c6436d0-9309-4f70-baa0-6a970c7d5e17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 1\n","Error : 0.0\n","Minimizer : [2. 2. 1.]\n"]}]},{"cell_type":"code","source":["W0 = np.array([0, 0.005, -2], dtype=float)\n","NewtonMethod(func1, jacobian_func, hessian_func, W0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jcZSAn-McI4","outputId":"88ff7ad8-c048-42fe-9664-91b6f15f583c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 1\n","Error : 1.1102230246251565e-16\n","Minimizer : [2. 2. 1.]\n"]}]},{"cell_type":"code","source":["W0 = np.array([200,300,5000], dtype=float)\n","NewtonMethod(func1, jacobian_func, hessian_func, W0)"],"metadata":{"id":"19H38AiHpDPd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb6ce940-8f36-42b0-de54-9947a94abe17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 1\n","Error : 5.85238816540084e-13\n","Minimizer : [2. 2. 1.]\n"]}]},{"cell_type":"code","source":["def func2(x):\n","    \"\"\"\n","    Objective function 2 whose roots are the ones to find.\n","    \"\"\"\n","    return 100*((x[1]-x[0]**2)**2) + (1-x[0])**2"],"metadata":{"id":"c9ZI6JFmSoar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jacobian_func = jacobian(func2)\n","hessian_func = hessian(func2)"],"metadata":{"id":"glBG6kJfVLfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["W0 = np.array([-1.2, 1], dtype=float)\n","NewtonMethod(func2, jacobian_func, hessian_func, W0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zVb5l6GUUycb","outputId":"7874b00d-bee8-4f20-c49d-6bec0b99652d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 1\n","Error : 4.95094472322468\n","Minimizer : [-1.1752809   1.38067416]\n","Iteration Number : 2\n","Error : 3.75785864343104\n","Minimizer : [ 0.76311487 -3.17503385]\n","Iteration Number : 3\n","Error : 0.4317760753884038\n","Minimizer : [0.76342968 0.58282478]\n","Iteration Number : 4\n","Error : 0.05596406747375653\n","Minimizer : [0.99999531 0.94402732]\n","Iteration Number : 5\n","Error : 9.62477796681768e-06\n","Minimizer : [0.9999957  0.99999139]\n"]}]},{"cell_type":"code","source":["W0 = np.array([0, 1/400+10**-12], dtype=float)\n","NewtonMethod(func2, jacobian_func, hessian_func, W0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uY-Ywr9uUyeq","outputId":"713edbc2-eeb9-431c-e1c9-a749832b813e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 1\n","Error : 3.995006440463911\n","Minimizer : [2. 0.]\n","Iteration Number : 2\n","Error : 4.114254914080283\n","Minimizer : [1.99875156 3.99500625]\n","Iteration Number : 3\n","Error : 0.9968799797602049\n","Minimizer : [1.00031123 0.00373948]\n","Iteration Number : 4\n","Error : 0.0006926388451605293\n","Minimizer : [1.00030968 1.00061946]\n"]}]},{"cell_type":"code","source":["W0 = np.array([0, 0.005], dtype=float)\n","NewtonMethod(func2, jacobian_func, hessian_func, W0)"],"metadata":{"id":"re-bSpC8Uyid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Newton method fails for the vector [0, 0.005] --> Singular Matrix which cannot be Inverted\n","# --> Newton method is not a global optimizer, it cannot guarantee the convergence for every starting point"],"metadata":{"id":"VQwX3HcOVrzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"NFv3lAt8MKmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"la0cGcchLffF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9uN1jiA8Lfhw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"GmNetUoPLfj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5jxuUMz8Lflk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"UKhuR4dALfo_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"55TzjJ6MddK6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"A9947xADF5v1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ZHBwe8iYMrQH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def GlobalNewtonMethod(func, jacob_f, hessian_f, w0, epsilon = 0.001, nMax = 100, Mu = 2, c = 0.0001):\n","    i = 0\n","    \n","    jacobian_w = jacob_f(w0)\n","    min_eigen = -min(np.linalg.eigvals(hessian_f(w0)))\n","    Yk = Mu * max(10**-10, min_eigen)\n","    hessian_w_reg = hessian_f(w0) + np.dot(np.identity(hessian_f(w0).shape[0]), Yk)\n","    hessian_w_reg_inv = np.linalg.inv(hessian_w_reg)\n","    D = -np.dot(hessian_w_reg_inv, jacobian_w)\n","    error = np.linalg.norm(w0 - (w0 + D))\n","    #Looping as long as error is greater than epsilon or maximum number of iterations is not reached:\n","    while error > epsilon and i < nMax:\n","        i +=1\n","        w0 = (w0 + D)\n","        jacobian_w = jacob_f(w0)\n","        while func(w0+D) >= func(w0) + c*np.dot(np.transpose(D),jacobian_w):\n","          Yk = Mu*Yk\n","          hessian_w_reg = hessian_func(w0) + np.dot(np.identity(hessian_func(w0).shape[0]), Yk)\n","          hessian_w_reg_inv = np.linalg.inv(hessian_w_reg)\n","          D = -np.dot(hessian_w_reg_inv, jacobian_w)\n","\n","        error = np.linalg.norm(w0 - (w0 + D))\n","\n","    print(\"Iteration Number : {}\".format(i))\n","    print(\"Error : {}\".format(error))\n","    print(\"Minimizer : {}\".format(w0))\n"],"metadata":{"id":"wpNW93XaM000"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["W0 = np.array([-1.2, 1], dtype=float)\n","GlobalNewtonMethod(func=func2, jacob_f=jacobian_func, hessian_f=hessian_func, w0=W0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26_ubSQ3QMFi","outputId":"cb00d132-88b6-480e-e3bc-4d98f6d321f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 59\n","Error : 0.0008464258865713102\n","Minimizer : [ 0.0425455  -0.01105647]\n"]}]},{"cell_type":"code","source":["W0 = np.array([0, 1/400+10**-12], dtype=float)\n","GlobalNewtonMethod(func=func2, jacob_f=jacobian_func, hessian_f=hessian_func, w0=W0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1KKSCVqQd6G","outputId":"cab27298-2081-487f-d70d-e1405ba95b6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 79\n","Error : 0.00034205414867861386\n","Minimizer : [1.18541131 1.40620071]\n"]}]},{"cell_type":"code","source":["W0 = np.array([0, 0.005], dtype=float)\n","GlobalNewtonMethod(func=func2, jacob_f=jacobian_func, hessian_f=hessian_func, w0=W0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2bA4cIYSj4h","outputId":"09fda98e-47ff-4bb4-b593-4642f16d8c69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration Number : 71\n","Error : nan\n","Minimizer : [1.e+10 1.e+20]\n"]}]},{"cell_type":"code","source":["# The Global version of the Newton method converges for the vector [0, 0.005], which was divergent for the previous version of the method."],"metadata":{"id":"P7DSfdSrSzyK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"-Nph4ueNTGN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for mu in [0, 2, 5, 7, 17, 120]:\n","  print(\"Mu : {}\".format(mu))\n","  GlobalNewtonMethod(func=func2, jacob_f=jacobian_func, hessian_f=hessian_func, w0=W0, Mu=mu)\n","  print(\"###############################\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpFlo0PdQyHG","outputId":"d9a9e94d-73e7-45fb-e193-e09a8e0ffc74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mu : 0\n","Iteration Number : 1\n","Error : 3.76822190084106e-15\n","Minimizer : [1. 1.]\n","###############################\n","Mu : 2\n","Iteration Number : 1\n","Error : 2.832097600274806e-10\n","Minimizer : [1. 1.]\n","###############################\n","Mu : 5\n","Iteration Number : 1\n","Error : 7.079695247253446e-10\n","Minimizer : [1. 1.]\n","###############################\n","Mu : 7\n","Iteration Number : 1\n","Error : 9.911834452894007e-10\n","Minimizer : [1. 1.]\n","###############################\n","Mu : 17\n","Iteration Number : 1\n","Error : 2.4071301881692756e-09\n","Minimizer : [1. 1.]\n","###############################\n","Mu : 120\n","Iteration Number : 1\n","Error : 1.6991680508820098e-08\n","Minimizer : [0.99999999 0.99999999]\n","###############################\n"]}]},{"cell_type":"code","source":["import time"],"metadata":{"id":"6Mvkl0qBTVIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for c in [10**-5, 10**-3, 0.1, 1, 10, 100]:\n","  print(\"C : {}\".format(c))\n","  start_time = time.time()\n","  GlobalNewtonMethod(func=func2, jacob_f=jacobian_func, hessian_f=hessian_func, w0=W0, c=c)\n","  print(\"Processing time(s): {}\".format(time.time() - start_time))\n","  print(\"###############################\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezYVcJA_Rkwp","outputId":"2a8e50f9-f801-410b-8ebc-653acce3f6e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C : 1e-05\n","Iteration Number : 1\n","Error : 2.832097600274806e-10\n","Minimizer : [1. 1.]\n","Processing time(s): 0.018755197525024414\n","###############################\n","C : 0.001\n","Iteration Number : 1\n","Error : 2.832097600274806e-10\n","Minimizer : [1. 1.]\n","Processing time(s): 0.016400814056396484\n","###############################\n","C : 0.1\n","Iteration Number : 1\n","Error : 2.832097600274806e-10\n","Minimizer : [1. 1.]\n","Processing time(s): 0.015430927276611328\n","###############################\n","C : 1\n","Iteration Number : 1\n","Error : 1.6054197309469919e-13\n","Minimizer : [1. 1.]\n","Processing time(s): 0.22468876838684082\n","###############################\n","C : 10\n","Iteration Number : 1\n","Error : nan\n","Minimizer : [1. 1.]\n","Processing time(s): 5.031253337860107\n","###############################\n","C : 100\n","Iteration Number : 1\n","Error : nan\n","Minimizer : [1. 1.]\n","Processing time(s): 4.960794448852539\n","###############################\n"]}]},{"cell_type":"code","source":["# The method is not very sensitive to changes for values in Mu or C (converges in one iteration + very small change in the error)\n","# the only noticeable difference is in the Processing time"],"metadata":{"id":"rOb1ERCiS7Vl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ue_eAQB8TM-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"PJlsBt2WTNBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"hZkoolAhiGYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"NLtLVJUXsWkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def logistic_loss(X,Y,w,reg_lambda):\n","    return np.sum(np.log(1 + np.exp(-Y*(X.dot(w))))) + 0.5*reg_lambda*(w**2).sum()"],"metadata":{"id":"Ftc9MRxviGbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def logistic_grad(X,Y,w,reg_lambda):\n","    return (-Y/(1 + np.exp(Y*(X.dot(w)))))*X + reg_lambda*w"],"metadata":{"id":"fBneNs7E0yI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def logistic_hessian(X,Y,w,reg_lambda):\n","    return (1/(1 + np.exp(Y*(X.dot(w))))) * (np.exp(Y*(X.dot(w)))) * (X.dot(np.transpose(X))) + reg_lambda*np.identity(len(w))"],"metadata":{"id":"kecvFd0F1BfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"SRrt8sLz1Bj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def subsampled_newton(X,Y,w0,reg_lambda,subsample_size):\n","    loss = logistic_loss(X,Y,w0,reg_lambda)\n","    grad = logistic_grad(X,Y,w0,reg_lambda)\n","    hessian = logistic_hessian(X,Y,w0,reg_lambda)\n","    n,d = X.shape\n","    \n","    max_niters = 150\n","    error = 100\n","    epsilon = 0.005\n","    c = 0.0001\n","    Mu = 2\n","\n","    start_time = time.time()\n","    i = 0\n","    while error > epsilon and i < max_niters:\n","        i +=1\n","\n","        # compute the subsample Hessians\n","        idx = np.random.choice(n,subsample_size)\n","        p_sub = 1.0/subsample_size\n","        X_sub = X[idx,:]\n","\n","        # define gradient for subsampling problem:\n","        grad_sub = logistic_grad(X_sub,Y[idx],w0,reg_lambda)\n","        grad_sub = grad_sub * p_sub\n","        \n","        # define hessian for subsampling problem:\n","        hess_sub = logistic_hessian(X_sub,Y[idx],w0,reg_lambda)\n","        hess_sub = hess_sub * p_sub\n","\n","        min_eigen = -min(np.linalg.eigvals(hess_sub))\n","        Yk = Mu * max(10**-10, min_eigen)\n","        hessian_w_reg = hess_sub + np.dot(np.identity(subsample_size), Yk)\n","        hessian_w_reg_inv = np.linalg.inv(hessian_w_reg)\n","        D = -np.dot(hessian_w_reg_inv, grad_sub)\n","        error = np.linalg.norm(w0 - (w0 + D))\n","\n","        while logistic_loss(w0+D) >= logistic_loss(w0) + c*np.dot(np.transpose(D),grad_sub):\n","          Yk = Mu*Yk\n","          hessian_w_reg = hess_sub + np.dot(np.identity(subsample_size), Yk)\n","          hessian_w_reg_inv = np.linalg.inv(hessian_w_reg)\n","          D = -np.dot(hessian_w_reg_inv, grad_sub)\n","\n","        error = np.linalg.norm(w0 - (w0 + D))\n","        w0 = (w0 + D)\n","        print(\"Iteration Number : {}\".format(i))\n","        print(\"Error : {}\".format(error))\n","        print(\"Minimizer : {}\".format(w0))\n","\n"],"metadata":{"id":"T3dFzwV49GXe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Eirq668_9Gbz"},"execution_count":null,"outputs":[]}]}